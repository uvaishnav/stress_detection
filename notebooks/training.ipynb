{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/uvaishnav/stress_detection'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os\n",
    "# os.chdir('../')\n",
    "# %pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocess Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_null_columns( df):\n",
    "        \"\"\"Remove columns with all null values.\"\"\"\n",
    "        return df.dropna(axis=1, how='all')\n",
    "\n",
    "def remove_highly_correlated_features(df):\n",
    "    \"\"\"Remove columns with high correlation.\"\"\"\n",
    "    highly_corelated_features = {'HRV_IQRNN', 'HRV_CVNN', 'HRV_SDSD', 'BVP_psd_std', 'HRV_MaxNN', 'EDA_SCL_mean', 'HRV_MCVNN', 'HRV_CVSD', 'HRV_RMSSD', 'HRV_pNN20', 'EDA_SCR_amplitude_mean'}\n",
    "    return df.drop(columns=highly_corelated_features, errors='ignore')\n",
    "\n",
    "def get_important_features(df):\n",
    "    important_features = ['ACC_Z_mean', 'ACC_Y_mean', 'ACC_X_mean',\n",
    "       'ACC_magnitude_std', 'EDA_mean', 'TEMP_mean',]  \n",
    "    return df[important_features]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = pd.read_csv(\"data/features/extracted_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BVP_mean</th>\n",
       "      <th>BVP_std</th>\n",
       "      <th>ACC_X_mean</th>\n",
       "      <th>ACC_Y_mean</th>\n",
       "      <th>ACC_Z_mean</th>\n",
       "      <th>TEMP_mean</th>\n",
       "      <th>EDA_mean</th>\n",
       "      <th>EDA_std</th>\n",
       "      <th>BVP_psd_mean</th>\n",
       "      <th>BVP_psd_std</th>\n",
       "      <th>...</th>\n",
       "      <th>HRV_pNN20</th>\n",
       "      <th>HRV_MinNN</th>\n",
       "      <th>HRV_MaxNN</th>\n",
       "      <th>HRV_HTI</th>\n",
       "      <th>HRV_TINN</th>\n",
       "      <th>EDA_SCL_mean</th>\n",
       "      <th>EDA_SCR_mean</th>\n",
       "      <th>EDA_SCR_peaks</th>\n",
       "      <th>EDA_SCR_amplitude_mean</th>\n",
       "      <th>stress_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013829</td>\n",
       "      <td>2.291471</td>\n",
       "      <td>27.861877</td>\n",
       "      <td>-25.862279</td>\n",
       "      <td>19.613106</td>\n",
       "      <td>35.460832</td>\n",
       "      <td>1.217864</td>\n",
       "      <td>0.078524</td>\n",
       "      <td>0.010645</td>\n",
       "      <td>0.070833</td>\n",
       "      <td>...</td>\n",
       "      <td>90.476190</td>\n",
       "      <td>546.875</td>\n",
       "      <td>9515.625</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>281.250</td>\n",
       "      <td>1.221463</td>\n",
       "      <td>-0.002300</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.994065</td>\n",
       "      <td>33.813407</td>\n",
       "      <td>-7.297195</td>\n",
       "      <td>24.827901</td>\n",
       "      <td>35.516166</td>\n",
       "      <td>1.195514</td>\n",
       "      <td>0.085250</td>\n",
       "      <td>0.008269</td>\n",
       "      <td>0.059856</td>\n",
       "      <td>...</td>\n",
       "      <td>78.125000</td>\n",
       "      <td>437.500</td>\n",
       "      <td>2640.625</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>328.125</td>\n",
       "      <td>1.194588</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.465470</td>\n",
       "      <td>43.838196</td>\n",
       "      <td>-1.755778</td>\n",
       "      <td>35.592263</td>\n",
       "      <td>35.519333</td>\n",
       "      <td>1.115099</td>\n",
       "      <td>0.030581</td>\n",
       "      <td>0.005122</td>\n",
       "      <td>0.044267</td>\n",
       "      <td>...</td>\n",
       "      <td>74.324324</td>\n",
       "      <td>500.000</td>\n",
       "      <td>1281.250</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>250.000</td>\n",
       "      <td>1.115679</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000023</td>\n",
       "      <td>0.294084</td>\n",
       "      <td>44.846485</td>\n",
       "      <td>-11.244263</td>\n",
       "      <td>42.561256</td>\n",
       "      <td>35.546331</td>\n",
       "      <td>1.064092</td>\n",
       "      <td>0.062517</td>\n",
       "      <td>0.003477</td>\n",
       "      <td>0.042426</td>\n",
       "      <td>...</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>609.375</td>\n",
       "      <td>1015.625</td>\n",
       "      <td>6.545455</td>\n",
       "      <td>156.250</td>\n",
       "      <td>1.063762</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.897162</td>\n",
       "      <td>44.016370</td>\n",
       "      <td>-9.123131</td>\n",
       "      <td>40.483478</td>\n",
       "      <td>35.669996</td>\n",
       "      <td>1.020672</td>\n",
       "      <td>0.071941</td>\n",
       "      <td>0.014656</td>\n",
       "      <td>0.089303</td>\n",
       "      <td>...</td>\n",
       "      <td>82.857143</td>\n",
       "      <td>531.250</td>\n",
       "      <td>1265.625</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>234.375</td>\n",
       "      <td>1.020715</td>\n",
       "      <td>-0.000169</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BVP_mean   BVP_std  ACC_X_mean  ACC_Y_mean  ACC_Z_mean  TEMP_mean  \\\n",
       "0  0.013829  2.291471   27.861877  -25.862279   19.613106  35.460832   \n",
       "1  0.000731  0.994065   33.813407   -7.297195   24.827901  35.516166   \n",
       "2  0.001173  0.465470   43.838196   -1.755778   35.592263  35.519333   \n",
       "3 -0.000023  0.294084   44.846485  -11.244263   42.561256  35.546331   \n",
       "4  0.000576  0.897162   44.016370   -9.123131   40.483478  35.669996   \n",
       "\n",
       "   EDA_mean   EDA_std  BVP_psd_mean  BVP_psd_std  ...  HRV_pNN20  HRV_MinNN  \\\n",
       "0  1.217864  0.078524      0.010645     0.070833  ...  90.476190    546.875   \n",
       "1  1.195514  0.085250      0.008269     0.059856  ...  78.125000    437.500   \n",
       "2  1.115099  0.030581      0.005122     0.044267  ...  74.324324    500.000   \n",
       "3  1.064092  0.062517      0.003477     0.042426  ...  77.777778    609.375   \n",
       "4  1.020672  0.071941      0.014656     0.089303  ...  82.857143    531.250   \n",
       "\n",
       "   HRV_MaxNN    HRV_HTI  HRV_TINN  EDA_SCL_mean  EDA_SCR_mean  EDA_SCR_peaks  \\\n",
       "0   9515.625  14.000000   281.250      1.221463     -0.002300              4   \n",
       "1   2640.625  10.666667   328.125      1.194588      0.000375              6   \n",
       "2   1281.250   6.166667   250.000      1.115679     -0.000198              5   \n",
       "3   1015.625   6.545455   156.250      1.063762      0.000854              5   \n",
       "4   1265.625   8.750000   234.375      1.020715     -0.000169              5   \n",
       "\n",
       "   EDA_SCR_amplitude_mean  stress_label  \n",
       "0                0.000020             0  \n",
       "1                0.000021             0  \n",
       "2                0.000010             0  \n",
       "3                0.000013             0  \n",
       "4                0.000031             0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = data.drop(columns=['stress_label'])\n",
    "y = data['stress_label']\n",
    "\n",
    "# Remove columns with all null values\n",
    "X = remove_null_columns(X)\n",
    "\n",
    "# Remove highly correlated features\n",
    "X = remove_highly_correlated_features(X)\n",
    "\n",
    "# Get the most important features\n",
    "X = get_important_features(X)\n",
    "\n",
    "# Normalize the features\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Convert back to DataFrame to add the target variable\n",
    "preprocessed_features = pd.DataFrame(X, columns=get_important_features(data).columns)\n",
    "preprocessed_features['stress_label'] = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after resampling:\n",
      "stress_label\n",
      "0    2044\n",
      "1    2044\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate features and target variable\n",
    "X = preprocessed_features.drop(columns=['stress_label'])\n",
    "y = preprocessed_features['stress_label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Apply SMOTE to balance the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Display the class distribution after resampling\n",
    "print(\"Class distribution after resampling:\")\n",
    "print(pd.Series(y_train_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier\n",
      "Confusion Matrix:\n",
      "[[506   6]\n",
      " [  8  58]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Non-Stress       0.98      0.99      0.99       512\n",
      "      Stress       0.91      0.88      0.89        66\n",
      "\n",
      "    accuracy                           0.98       578\n",
      "   macro avg       0.95      0.93      0.94       578\n",
      "weighted avg       0.98      0.98      0.98       578\n",
      "\n",
      "\n",
      "\n",
      "Model: LogisticRegression\n",
      "Confusion Matrix:\n",
      "[[355 157]\n",
      " [ 23  43]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Non-Stress       0.94      0.69      0.80       512\n",
      "      Stress       0.21      0.65      0.32        66\n",
      "\n",
      "    accuracy                           0.69       578\n",
      "   macro avg       0.58      0.67      0.56       578\n",
      "weighted avg       0.86      0.69      0.74       578\n",
      "\n",
      "\n",
      "\n",
      "Model: SVC\n",
      "Confusion Matrix:\n",
      "[[469  43]\n",
      " [  7  59]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Non-Stress       0.99      0.92      0.95       512\n",
      "      Stress       0.58      0.89      0.70        66\n",
      "\n",
      "    accuracy                           0.91       578\n",
      "   macro avg       0.78      0.90      0.83       578\n",
      "weighted avg       0.94      0.91      0.92       578\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Define a function to train and evaluate models\n",
    "def train_and_evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Model: {model.__class__.__name__}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Non-Stress', 'Stress']))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Initialize models\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    LogisticRegression(random_state=42),\n",
    "    SVC(random_state=42)\n",
    "]\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model in models:\n",
    "    train_and_evaluate_model(model, X_train_resampled, y_train_resampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
